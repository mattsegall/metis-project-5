{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unlimited-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "meaningful-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('childrens_book_df_with_sounds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "scheduled-dependence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>NLP_Text</th>\n",
       "      <th>Readable_Text</th>\n",
       "      <th>Readable_Passage_Len</th>\n",
       "      <th>oo</th>\n",
       "      <th>ou</th>\n",
       "      <th>ow</th>\n",
       "      <th>oi</th>\n",
       "      <th>...</th>\n",
       "      <th>ce</th>\n",
       "      <th>ci</th>\n",
       "      <th>cy</th>\n",
       "      <th>ge</th>\n",
       "      <th>dge</th>\n",
       "      <th>gi</th>\n",
       "      <th>gy</th>\n",
       "      <th>kn</th>\n",
       "      <th>wr</th>\n",
       "      <th>gn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prince Prigio</td>\n",
       "      <td>Andrew Lang</td>\n",
       "      <td>I</td>\n",
       "      <td>lcb chapter heading picture p1jpg rcb fairies ...</td>\n",
       "      <td>How the Fairies were not Invited to Court. Onc...</td>\n",
       "      <td>5500</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>0.008182</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prince Prigio</td>\n",
       "      <td>Andrew Lang</td>\n",
       "      <td>II</td>\n",
       "      <td>lcb chapter heading picture p9jpg rcb prince p...</td>\n",
       "      <td>Prince Prigio and his Family. Well, the little...</td>\n",
       "      <td>3210</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.010280</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prince Prigio</td>\n",
       "      <td>Andrew Lang</td>\n",
       "      <td>III</td>\n",
       "      <td>firedrake people like prigio dear papa king gr...</td>\n",
       "      <td>About the Firedrake. Of all the people who did...</td>\n",
       "      <td>8008</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.012488</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prince Prigio</td>\n",
       "      <td>Andrew Lang</td>\n",
       "      <td>IV</td>\n",
       "      <td>prince prigio deserted everybody meanwhile pri...</td>\n",
       "      <td>How Prince Prigio was Deserted by Everybody. M...</td>\n",
       "      <td>4607</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.008465</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prince Prigio</td>\n",
       "      <td>Andrew Lang</td>\n",
       "      <td>V</td>\n",
       "      <td>prince prigio found garret prince walked room ...</td>\n",
       "      <td>What Prince Prigio found in the Garret. The pr...</td>\n",
       "      <td>1412</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Title         Author Chapter  \\\n",
       "0  Prince Prigio    Andrew Lang       I   \n",
       "1  Prince Prigio    Andrew Lang      II   \n",
       "2  Prince Prigio    Andrew Lang     III   \n",
       "3  Prince Prigio    Andrew Lang      IV   \n",
       "4  Prince Prigio    Andrew Lang       V   \n",
       "\n",
       "                                            NLP_Text  \\\n",
       "0  lcb chapter heading picture p1jpg rcb fairies ...   \n",
       "1  lcb chapter heading picture p9jpg rcb prince p...   \n",
       "2  firedrake people like prigio dear papa king gr...   \n",
       "3  prince prigio deserted everybody meanwhile pri...   \n",
       "4  prince prigio found garret prince walked room ...   \n",
       "\n",
       "                                       Readable_Text  Readable_Passage_Len  \\\n",
       "0  How the Fairies were not Invited to Court. Onc...                  5500   \n",
       "1  Prince Prigio and his Family. Well, the little...                  3210   \n",
       "2  About the Firedrake. Of all the people who did...                  8008   \n",
       "3  How Prince Prigio was Deserted by Everybody. M...                  4607   \n",
       "4  What Prince Prigio found in the Garret. The pr...                  1412   \n",
       "\n",
       "         oo        ou        ow        oi  ...        ce        ci        cy  \\\n",
       "0  0.002727  0.008182  0.001818  0.000364  ...  0.003636  0.000000  0.000000   \n",
       "1  0.004050  0.010280  0.004984  0.000000  ...  0.005296  0.000623  0.000000   \n",
       "2  0.001873  0.012488  0.002997  0.000874  ...  0.003621  0.000125  0.000125   \n",
       "3  0.001954  0.008465  0.004124  0.000434  ...  0.006295  0.000434  0.000000   \n",
       "4  0.007790  0.005666  0.003541  0.000708  ...  0.004249  0.000000  0.000708   \n",
       "\n",
       "         ge       dge        gi        gy        kn        wr        gn  \n",
       "0  0.000364  0.000000  0.000545  0.000000  0.000545  0.000000  0.000545  \n",
       "1  0.001558  0.000000  0.001869  0.000000  0.000623  0.000312  0.000312  \n",
       "2  0.002498  0.000000  0.002872  0.000000  0.000500  0.000250  0.000250  \n",
       "3  0.000868  0.000217  0.002388  0.000217  0.000868  0.000217  0.000217  \n",
       "4  0.000000  0.000000  0.000708  0.000000  0.000000  0.000708  0.000000  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "industrial-straight",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-8d54d74d6383>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['NLP_Text'] = df['NLP_Text'].str.replace('\\d+', '') #remove numbers\n"
     ]
    }
   ],
   "source": [
    "#clean further\n",
    "df['NLP_Text'] = df['NLP_Text'].str.replace('\\d+', '') #remove numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "surprising-laundry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lcb chapter heading picture pjpg rcb prince prigio family well little prince grew think told prigio well think clever argued nurse soon could speak soon argued like washed soap got eyes however told pores skin could healthy washed ceased resist reasonable argued father see kings rich beggars poor king little greedy poached eggs plumcake afternoon tea many persons went without dinner king surprised hurt remarks boxed prince ears saying teach clever lad remembered awful curse oldest fairy sorry rudeness queen prince ears boxed said force argument king went away rage lcb prigio reading book pjpg rcb indeed tell prince hated would go kitchen show cook make soup would visit poor people cottage teach make beds make plumpudding turniptops venison cutlets rusty bacon showed fencingmaster fence professional cricketer bowl instructed ratcatcher breeding terriers set sums chancellor exchequer assured astronomer royal sun go round earth part believe young ladies court disliked dancing spite good looks always asking read read said nt sneered said found found tutors masters horrid way correcting accent french teacher trying get german tutor eat peas knife endeavoured teach queendowager grandmother art long perfectly familiar fact knew everything better anybody else worst never wrong always said nt tell time went prince prigio two younger brothers everybody liked bit clever jolly prince alphonso third round fat goodhumoured brave lion prince enrico second tall thin little sad never clever love two cousins lrb approval dear parents rrb world said nice unaffected princes prigio nearly got country several wars clever foreign ambassadors pantouflia rich lazy country hated fighting unpleasant make people love prince prigio better'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "breeding-facility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<866x49878 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 600910 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count vectorize\n",
    "count_vectorizer = CountVectorizer(stop_words = 'english')\n",
    "words_count_vectorize = count_vectorizer.fit_transform(df.NLP_Text)\n",
    "words_count_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "whole-amsterdam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaamen</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abaft</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>...</th>\n",
       "      <th>zulamith</th>\n",
       "      <th>zulbazan</th>\n",
       "      <th>zylland</th>\n",
       "      <th>zytomar</th>\n",
       "      <th>ælueva</th>\n",
       "      <th>æneas</th>\n",
       "      <th>æsop</th>\n",
       "      <th>æsthetic</th>\n",
       "      <th>ætna</th>\n",
       "      <th>úprincess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866 rows × 49878 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aa  aaamen  aaron  ab  aback  abacus  abaft  abandon  abandoned  \\\n",
       "0     0       0      0   0      0       0      0        0          0   \n",
       "1     0       0      0   0      0       0      0        0          0   \n",
       "2     0       0      0   0      0       0      0        0          0   \n",
       "3     0       0      0   0      0       0      0        0          0   \n",
       "4     0       0      0   0      0       0      0        0          0   \n",
       "..   ..     ...    ...  ..    ...     ...    ...      ...        ...   \n",
       "861   0       0      0   0      0       0      0        0          0   \n",
       "862   0       0      0   0      0       0      0        0          0   \n",
       "863   0       0      0   0      0       0      0        0          0   \n",
       "864   0       0      0   0      0       0      0        0          0   \n",
       "865   0       0      0   0      0       0      0        0          0   \n",
       "\n",
       "     abandoning  ...  zulamith  zulbazan  zylland  zytomar  ælueva  æneas  \\\n",
       "0             0  ...         0         0        0        0       0      0   \n",
       "1             0  ...         0         0        0        0       0      0   \n",
       "2             0  ...         0         0        0        0       0      0   \n",
       "3             0  ...         0         0        0        0       0      0   \n",
       "4             0  ...         0         0        0        0       0      0   \n",
       "..          ...  ...       ...       ...      ...      ...     ...    ...   \n",
       "861           0  ...         0         0        0        0       0      0   \n",
       "862           0  ...         0         0        0        0       0      0   \n",
       "863           0  ...         0         0        0        0       0      0   \n",
       "864           0  ...         0         0        0        0       0      0   \n",
       "865           0  ...         0         0        0        0       0      0   \n",
       "\n",
       "     æsop  æsthetic  ætna  úprincess  \n",
       "0       0         0     0          0  \n",
       "1       0         0     0          0  \n",
       "2       0         0     0          0  \n",
       "3       0         0     0          0  \n",
       "4       0         0     0          0  \n",
       "..    ...       ...   ...        ...  \n",
       "861     0         0     0          0  \n",
       "862     0         0     0          0  \n",
       "863     0         0     0          0  \n",
       "864     0         0     0          0  \n",
       "865     0         0     0          0  \n",
       "\n",
       "[866 rows x 49878 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new word matrix as df\n",
    "features = count_vectorizer.get_feature_names()\n",
    "df_words_count_vec = pd.DataFrame(words_count_vectorize.toarray(), columns=features)\n",
    "df_words_count_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "proprietary-stephen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaamen</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abaft</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>...</th>\n",
       "      <th>zulamith</th>\n",
       "      <th>zulbazan</th>\n",
       "      <th>zylland</th>\n",
       "      <th>zytomar</th>\n",
       "      <th>ælueva</th>\n",
       "      <th>æneas</th>\n",
       "      <th>æsop</th>\n",
       "      <th>æsthetic</th>\n",
       "      <th>ætna</th>\n",
       "      <th>úprincess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866 rows × 49878 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aaamen  aaron   ab  aback  abacus  abaft  abandon  abandoned  \\\n",
       "0    0.0     0.0    0.0  0.0    0.0     0.0    0.0      0.0        0.0   \n",
       "1    0.0     0.0    0.0  0.0    0.0     0.0    0.0      0.0        0.0   \n",
       "2    0.0     0.0    0.0  0.0    0.0     0.0    0.0      0.0        0.0   \n",
       "3    0.0     0.0    0.0  0.0    0.0     0.0    0.0      0.0        0.0   \n",
       "4    0.0     0.0    0.0  0.0    0.0     0.0    0.0      0.0        0.0   \n",
       "..   ...     ...    ...  ...    ...     ...    ...      ...        ...   \n",
       "861  0.0     0.0    0.0  0.0    0.0     0.0    0.0      0.0        0.0   \n",
       "862  0.0     0.0    0.0  0.0    0.0     0.0    0.0      0.0        0.0   \n",
       "863  0.0     0.0    0.0  0.0    0.0     0.0    0.0      0.0        0.0   \n",
       "864  0.0     0.0    0.0  0.0    0.0     0.0    0.0      0.0        0.0   \n",
       "865  0.0     0.0    0.0  0.0    0.0     0.0    0.0      0.0        0.0   \n",
       "\n",
       "     abandoning  ...  zulamith  zulbazan  zylland  zytomar  ælueva  æneas  \\\n",
       "0           0.0  ...       0.0       0.0      0.0      0.0     0.0    0.0   \n",
       "1           0.0  ...       0.0       0.0      0.0      0.0     0.0    0.0   \n",
       "2           0.0  ...       0.0       0.0      0.0      0.0     0.0    0.0   \n",
       "3           0.0  ...       0.0       0.0      0.0      0.0     0.0    0.0   \n",
       "4           0.0  ...       0.0       0.0      0.0      0.0     0.0    0.0   \n",
       "..          ...  ...       ...       ...      ...      ...     ...    ...   \n",
       "861         0.0  ...       0.0       0.0      0.0      0.0     0.0    0.0   \n",
       "862         0.0  ...       0.0       0.0      0.0      0.0     0.0    0.0   \n",
       "863         0.0  ...       0.0       0.0      0.0      0.0     0.0    0.0   \n",
       "864         0.0  ...       0.0       0.0      0.0      0.0     0.0    0.0   \n",
       "865         0.0  ...       0.0       0.0      0.0      0.0     0.0    0.0   \n",
       "\n",
       "     æsop  æsthetic  ætna  úprincess  \n",
       "0     0.0       0.0   0.0        0.0  \n",
       "1     0.0       0.0   0.0        0.0  \n",
       "2     0.0       0.0   0.0        0.0  \n",
       "3     0.0       0.0   0.0        0.0  \n",
       "4     0.0       0.0   0.0        0.0  \n",
       "..    ...       ...   ...        ...  \n",
       "861   0.0       0.0   0.0        0.0  \n",
       "862   0.0       0.0   0.0        0.0  \n",
       "863   0.0       0.0   0.0        0.0  \n",
       "864   0.0       0.0   0.0        0.0  \n",
       "865   0.0       0.0   0.0        0.0  \n",
       "\n",
       "[866 rows x 49878 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#also try tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "words_tfidf = tfidf_vectorizer.fit_transform(df.NLP_Text)\n",
    "words_tfidf\n",
    "\n",
    "#new new matrix as df\n",
    "features = tfidf_vectorizer.get_feature_names()\n",
    "df_words_tfidf = pd.DataFrame(words_tfidf.toarray(), columns=features)\n",
    "df_words_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ranking-moses",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n",
      "/opt/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 words for topic # 0\n",
      "['palace', 'day', 'gold', 'fairy', 'long', 'good', 'shall', 'got', 'saw', 'time', 'away', 'great', 'prince', 'queen', 'went', 'came', 'princess', 'king', 'little', 'said']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 1\n",
      "['going', 'home', 'looked', 'good', 'oh', 'time', 'think', 'eyes', 'came', 'thought', 'aunt', 'mrs', 'went', 'miss', 'know', 'like', 'little', 'old', 'said', 'nt']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 2\n",
      "['thought', 'time', 'gilbert', 'good', 'oh', 'going', 'old', 'mr', 'little', 'miss', 'diana', 'know', 'think', 'davy', 'marilla', 'like', 'mrs', 'said', 'nt', 'anne']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 3\n",
      "['know', 'great', 'jimmy', 'time', 'way', 'long', 'chuck', 'johnny', 'big', 'billy', 'reddy', 'frog', 'green', 'fox', 'grandfather', 'rabbit', 'nt', 'old', 'mr', 'little']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 4\n",
      "['road', 'holy', 'boy', 'time', 'head', 'away', 'great', 'came', 'mowgli', 'sahib', 'good', 'like', 'know', 'mahbub', 'old', 'thy', 'thee', 'little', 'thou', 'said']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 5\n",
      "['time', 'dear', 'came', 'went', 'girls', 'boy', 'great', 'know', 'mother', 'said', 'away', 'boys', 'frank', 'mrs', 'good', 'like', 'jill', 'jack', 'little', 'nt']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 6\n",
      "['forth', 'away', 'eyes', 'world', 'good', 'time', 'new', 'people', 'shall', 'great', 'lady', 'life', 'hand', 'young', 'heart', 'long', 'mr', 'like', 'little', 'old']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 7\n",
      "['way', 'answered', 'eyes', 'away', 'think', 'dr', 'great', 'boys', 'know', 'mac', 'phebe', 'good', 'aunt', 'alec', 'uncle', 'said', 'like', 'little', 'nt', 'rose']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 8\n",
      "['told', 'long', 'saw', 'way', 'father', 'princess', 'young', 'wife', 'asked', 'little', 'took', 'day', 'answered', 'old', 'came', 'time', 'prince', 'went', 'king', 'said']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 9\n",
      "['doctor', 'long', 'came', 'lrb', 'ship', 'thought', 'hand', 'silver', 'think', 'sir', 'say', 'captain', 'cried', 'time', 'know', 'john', 'wendy', 'like', 'nt', 'said']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#nmf / count vec topics\n",
    "nmf = NMF(n_components=10, random_state=42)\n",
    "\n",
    "# fit the transfomed content with NMF\n",
    "nmf.fit(words_count_vectorize)\n",
    "\n",
    "# display the top 20 words for 10 topics\n",
    "for index,topic in enumerate(nmf.components_):\n",
    "    print(f\"The top 20 words for topic # {index}\")\n",
    "    print([count_vectorizer.get_feature_names()[i] for i in topic.argsort()[-20:]])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dirty-freeware",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 words for topic # 0\n",
      "['came', 'know', 'away', 'aunt', 'went', 'story', 'girl', 'felicity', 'good', 'mother', 'mr', 'mrs', 'beth', 'old', 'amy', 'laurie', 'like', 'little', 'said', 'nt']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 1\n",
      "['big', 'gun', 'river', 'hunting', 'nt', 'terrible', 'knew', 'pond', 'hunters', 'hounds', 'antlers', 'jay', 'green', 'stranger', 'deer', 'forest', 'paddy', 'sammy', 'hunter', 'lightfoot']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 2\n",
      "['henyard', 'dinner', 'henhouse', 'fat', 'little', 'mouse', 'hound', 'meadow', 'hens', 'rabbit', 'brown', 'nt', 'farmer', 'coyote', 'old', 'danny', 'bowser', 'fox', 'granny', 'reddy']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 3\n",
      "['jane', 'little', 'know', 'barry', 'think', 'like', 'oh', 'lynde', 'captain', 'miss', 'cornelia', 'mrs', 'said', 'matthew', 'gilbert', 'leslie', 'diana', 'nt', 'marilla', 'anne']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 4\n",
      "['like', 'joanna', 'shall', 'hand', 'shoreby', 'cried', 'good', 'returned', 'richard', 'shelton', 'lawless', 'nay', 'matcham', 'lord', 'said', 'sir', 'daniel', 'alan', 'dick', 'ye']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 5\n",
      "['hooty', 'hole', 'weasel', 'mrs', 'stub', 'boy', 'tree', 'shadow', 'sugarhouse', 'mouse', 'wood', 'brown', 'home', 'jumper', 'whitey', 'farmer', 'little', 'nt', 'timmy', 'whitefoot']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 6\n",
      "['little', 'pond', 'sammy', 'beaver', 'joe', 'laughing', 'otter', 'nt', 'brook', 'dam', 'spotty', 'smiling', 'mink', 'billy', 'pool', 'muskrat', 'grandfather', 'frog', 'paddy', 'jerry']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 7\n",
      "['flew', 'quack', 'river', 'dusky', 'gun', 'hunter', 'ducks', 'egg', 'nest', 'corn', 'boy', 'nt', 'crow', 'caw', 'brown', 'eggs', 'farmer', 'bowser', 'hooty', 'blacky']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 8\n",
      "['clever', 'cap', 'enrico', 'royal', 'princess', 'benson', 'alphonso', 'carpet', 'ambassador', 'lady', 'rosalind', 'remora', 'molinda', 'queen', 'majesty', 'said', 'firedrake', 'prigio', 'king', 'prince']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 9\n",
      "['dear', 'glen', 'ingleside', 'sophia', 'oliver', 'jims', 'cornelia', 'blythe', 'miss', 'dr', 'meredith', 'faith', 'mrs', 'mary', 'said', 'nt', 'jem', 'walter', 'susan', 'rilla']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nmf -> tf-idf=\n",
    "nmf = NMF(n_components=10, random_state=42)\n",
    "\n",
    "# fit the transfomed content with NMF\n",
    "nmf.fit(words_tfidf)\n",
    "\n",
    "# display the result\n",
    "for index,topic in enumerate(nmf.components_):\n",
    "    print(f\"The top 20 words for topic # {index}\")\n",
    "    print([tfidf_vectorizer.get_feature_names()[i] for i in topic.argsort()[-20:]])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "manual-school",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 words for topic # 0\n",
      "['young', 'came', 'new', 'life', 'ye', 'shall', 'good', 'great', 'heart', 'time', 'hand', 'people', 'mowgli', 'mr', 'long', 'alan', 'like', 'little', 'said', 'old']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 1\n",
      "['poor', 'shall', 'nt', 'way', 'silver', 'long', 'came', 'began', 'time', 'great', 'captain', 'little', 'cried', 'hand', 'good', 'like', 'sir', 'said', 'dick', 'ye']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 2\n",
      "['way', 'answered', 'nt', 'took', 'shall', 'long', 'saw', 'princess', 'away', 'great', 'like', 'day', 'old', 'time', 'prince', 'came', 'went', 'little', 'king', 'said']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 3\n",
      "['pilrig', 'corstorphine', 'unheard', 'rithmetic', 'jubal', 'locate', 'coverings', 'retorted', 'growing', 'summer', 'horns', 'cow', 'advocate', 'bossy', 'knobs', 'hanging', 'new', 'ones', 'rags', 'antlers']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 4\n",
      "['way', 'children', 'mother', 'boys', 'michael', 'cried', 'kilmeny', 'know', 'darling', 'john', 'time', 'eric', 'nt', 'knew', 'hook', 'hunter', 'said', 'paddy', 'wendy', 'lightfoot']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 5\n",
      "['old', 'make', 'mother', 'asked', 'great', 'shall', 'poor', 'tom', 'dear', 'know', 'came', 'went', 'boys', 'mrs', 'away', 'good', 'like', 'said', 'little', 'nt']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 6\n",
      "['mr', 'say', 'diana', 'time', 'story', 'old', 'girl', 'good', 'miss', 'going', 'oh', 'know', 'marilla', 'little', 'think', 'mrs', 'like', 'said', 'anne', 'nt']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 7\n",
      "['world', 'head', 'away', 'holy', 'came', 'road', 'time', 'great', 'boy', 'like', 'good', 'sahib', 'know', 'mahbub', 'thy', 'little', 'old', 'thee', 'thou', 'said']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 8\n",
      "['grandfather', 'away', 'rabbit', 'great', 'right', 'billy', 'big', 'brown', 'long', 'fox', 'know', 'way', 'reddy', 'time', 'green', 'said', 'mr', 'old', 'little', 'nt']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 9\n",
      "['aunt', 'going', 'looked', 'oh', 'home', 'good', 'eyes', 'time', 'think', 'thought', 'miss', 'came', 'went', 'know', 'mrs', 'like', 'old', 'little', 'said', 'nt']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lda on count vec\n",
    "LDA = LatentDirichletAllocation(n_components = 10, n_jobs = -2, random_state = 42)\n",
    "\n",
    "# fit the transfomed content with LDA\n",
    "LDA.fit(words_count_vectorize)\n",
    "\n",
    "# display the result\n",
    "for index,topic in enumerate(LDA.components_):\n",
    "    print(f\"The top 20 words for topic # {index}\")\n",
    "    print([count_vectorizer.get_feature_names()[i] for i in topic.argsort()[-20:]])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "operational-playback",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 words for topic # 0\n",
      "['rosetta', 'advocate', 'eunice', 'gazelle', 'thyra', 'trevlyn', 'hoppyhippyhippyhopo', 'petru', 'really', 'coils', 'gluckstein', 'gibbet', 'executioner', 'thomson', 'lillian', 'waking', 'kitten', 'molinda', 'firedrake', 'remora']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 1\n",
      "['theseus', 'mcdougal', 'falkenstein', 'swordbelt', 'henderland', 'cheque', 'jason', 'turretstair', 'fiske', 'ahmed', 'gluckstein', 'butler', 'tackleton', 'molinda', 'alphonso', 'enrico', 'maimie', 'benson', 'firedrake', 'daintyfoot']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 2\n",
      "['tunstall', 'risingham', 'gloucester', 'alphonso', 'rankeillor', 'bennet', 'falkenstein', 'holywood', 'joanna', 'remora', 'hoseason', 'riach', 'shoreby', 'foxham', 'shelton', 'lawless', 'matcham', 'timmy', 'firedrake', 'daniel']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 3\n",
      "['ferries', 'silverlaced', 'speers', 'lettervore', 'tenantry', 'herhe', 'henderland', 'envies', 'lettermore', 'lilly', 'enrico', 'waterpath', 'salome', 'gluckstein', 'spooneful', 'cubical', 'maclean', 'water', 'babies', 'outthe']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 4\n",
      "['twothree', 'whaups', 'laith', 'guddling', 'crosstarrie', 'maccoll', 'shag', 'pockmarked', 'nainsel', 'cushatdove', 'intrusted', 'sidecoat', 'cushatdoves', 'grill', 'seatrousers', 'pox', 'corrynakiegh', 'cotch', 'cotched', 'bouman']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 5\n",
      "['cutlets', 'turniptops', 'cricketer', 'proclamations', 'quakers', 'legree', 'waggon', 'andy', 'backstairs', 'simeon', 'royaliness', 'butler', 'phineas', 'kelso', 'benson', 'loker', 'scrooge', 'chloe', 'haley', 'eliza']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 6\n",
      "['away', 'fox', 'way', 'bowser', 'paddy', 'whitefoot', 'good', 'mr', 'time', 'know', 'blacky', 'mrs', 'like', 'reddy', 'anne', 'old', 'lightfoot', 'little', 'said', 'nt']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 7\n",
      "['tracy', 'connors', 'snodgrass', 'sahib', 'limes', 'jungle', 'junipertree', 'pickwick', 'larry', 'mahbub', 'gordons', 'baucis', 'molinda', 'philemon', 'mowgli', 'lindsay', 'williamson', 'gordon', 'kilmeny', 'eric']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 8\n",
      "['diversion', 'braiding', 'mcpherson', 'herds', 'pastured', 'hoar', 'pelion', 'thessaly', 'grumblings', 'fountained', 'oread', 'outmost', 'horrider', 'thebes', 'dewless', 'barearmed', 'plumfield', 'glaucon', 'aglaia', 'outlittle']\n",
      "\n",
      "\n",
      "The top 20 words for topic # 9\n",
      "['ethiopian', 'leopard', 'sticklyprickly', 'balkis', 'jaguar', 'chestnuttrees', 'hemlocks', 'pau', 'peers', 'poplartrees', 'yellows', 'searches', 'mapletrees', 'beechtrees', 'suleimanbindaoud', 'tegumai', 'brambletangle', 'orchard', 'pandora', 'outkilmeny']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LDA / tf-idf\n",
    "LDA = LatentDirichletAllocation(n_components = 10, n_jobs = -2, random_state = 42)\n",
    "\n",
    "# fit the transfomed content with LDA\n",
    "LDA.fit(words_tfidf)\n",
    "\n",
    "# display the result\n",
    "for index,topic in enumerate(LDA.components_):\n",
    "    print(f\"The top 20 words for topic # {index}\")\n",
    "    print([tfidf_vectorizer.get_feature_names()[i] for i in topic.argsort()[-20:]])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-phase",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
